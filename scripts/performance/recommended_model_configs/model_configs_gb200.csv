task,model,size,system,dtype,num_gpus,seq_len,tp_size,pp_size,cp_size,ep_size,vp_size,mbs,gbs,etp_size,cuda_graphs,use_mcore_fsdp,recompute_layers,activation_offload_layers,recompute_modules
lora,llama3,70b,gb200,fp8,8.0,2048.0,1.0,4.0,1.0,1.0,20.0,1.0,64.0,,1,0,0,0,
lora,llama3,70b,gb200,bf16,8.0,2048.0,1.0,4.0,1.0,1.0,20.0,1.0,64.0,,1,0,0,0,
lora,llama3,8b,gb200,bf16,8.0,16384.0,1.0,1.0,1.0,1.0,1.0,1.0,8.0,,1,0,0,0,
lora,llama3,8b,gb200,fp8,8.0,16384.0,1.0,1.0,1.0,1.0,1.0,1.0,8.0,,1,0,0,0,
lora,llama31,405b,gb200,fp8,32.0,2048.0,4.0,4.0,1.0,1.0,16.0,1.0,32.0,,1,0,0,0,
lora,llama31,405b,gb200,bf16,32.0,2048.0,4.0,4.0,1.0,1.0,16.0,1.0,32.0,,1,0,0,0,
pre_train,gpt3,175b,gb200,bf16,128.0,2048.0,4.0,4.0,1.0,1.0,12.0,2.0,256.0,,1,0,0,0,
pre_train,gpt3,175b,gb200,fp8,128.0,2048.0,4.0,4.0,1.0,1.0,12.0,2.0,256.0,,1,0,0,0,
pre_train,llama3,8b,gb200,bf16,8.0,8192.0,1.0,1.0,1.0,1.0,1.0,2.0,128.0,,1,0,0,0,
pre_train,llama3,8b,gb200,fp8,8.0,8192.0,1.0,1.0,1.0,1.0,1.0,4.0,128.0,,1,0,0,0,
pre_train,llama3,70b,gb200,fp8,64.0,8192.0,1.0,1.0,1.0,1.0,1.0,1.0,128.0,,0,1,0,0,
pre_train,llama3,70b,gb200,bf16,64.0,8192.0,1.0,1.0,1.0,1.0,1.0,1.0,128.0,,0,1,20,0,
pre_train,llama31,405b,gb200,bf16,128.0,8192.0,4.0,8.0,2.0,1.0,8.0,1.0,64.0,,0,0,0,0,
pre_train,llama31,405b,gb200,fp8,128.0,8192.0,4.0,8.0,2.0,1.0,8.0,1.0,64.0,,0,0,0,0,
pre_train,mixtral,8x7b,gb200,bf16,64.0,4096.0,1.0,1.0,1.0,8.0,1.0,2.0,256.0,,1,0,0,0,
pre_train,mixtral,8x7b,gb200,fp8,64.0,4096.0,1.0,1.0,1.0,8.0,1.0,2.0,256.0,,1,0,0,0,
pre_train,nemotron4,15b,gb200,bf16,64.0,4096.0,1.0,1.0,1.0,1.0,1.0,2.0,256.0,,1,0,0,0,
pre_train,nemotron4,15b,gb200,fp8,64.0,4096.0,1.0,1.0,1.0,1.0,1.0,2.0,256.0,,1,0,0,0,
pre_train,nemotron4,340b,gb200,bf16,128.0,4096.0,4.0,8.0,1.0,1.0,12.0,1.0,32.0,,0,0,0,0,
pre_train,nemotron4,340b,gb200,fp8,128.0,4096.0,8.0,4.0,1.0,1.0,12.0,1.0,32.0,,1,0,0,0,
pre_train,deepseek,v3,gb200,bf16,1024.0,4096.0,1.0,16.0,1.0,64.0,1.0,1.0,8192.0,,0,0,0,0,core_attn/mla_up_proj
pre_train,deepseek,v3,gb200,bf16,256.0,4096.0,2.0,4.0,1.0,64.0,1.0,1.0,2048.0,1,0,0,0,0,core_attn
pre_train,deepseek,v3,gb200,bf16,128.0,4096.0,2.0,4.0,1.0,32.0,1.0,1.0,1024.0,1,0,0,0,0,core_attn
pre_train,nemotronh,8b,gb200,fp8,8,8192,1,1,1,1,1,2,128,,1,0,0,0,
pre_train,nemotronh,47b,gb200,fp8,64,8192,2,1,1,1,1,1,192,,1,0,0,0,
pre_train,nemotronh,56b,gb200,fp8,64,8192,2,1,1,1,1,1,192,,1,0,0,0,
pre_train,nemotronh,56b,gb200,fp8,256,8192,2,1,1,1,1,1,768,,1,0,0,0,
pre_train,llama4,e16,gb200,bf16,64.0,8192.0,1.0,1.0,1.0,16.0,1.0,1.0,1024.0,1.0,0,0,0,0,
pre_train,llama4,e128,gb200,bf16,128.0,8192.0,1.0,2.0,1.0,64.0,12.0,1.0,1024.0,1.0,0,0,0,0,
pre_train,vlm_llama4,e16,gb200,bf16,64.0,8192.0,1.0,1.0,1.0,16.0,1.0,1.0,1024.0,1.0,0,0,0,0,
pre_train,vlm_llama4,e128,gb200,bf16,128.0,8192.0,1.0,1.0,2.0,128.0,1.0,1.0,1024.0,1.0,0,0,0,0,
sft,llama3,8b,gb200,fp8,8.0,16384.0,1.0,1.0,1.0,1.0,1.0,1.0,8.0,,1,0,0,0,
sft,llama3,8b,gb200,bf16,8.0,16384.0,1.0,1.0,1.0,1.0,1.0,1.0,8.0,,1,0,0,0,
sft,llama3,70b,gb200,bf16,32.0,4096.0,2.0,4.0,1.0,1.0,5.0,1.0,32.0,,1,0,0,0,
sft,llama3,70b,gb200,fp8,32.0,4096.0,2.0,4.0,1.0,1.0,5.0,1.0,32.0,,1,0,0,0,
